### Kudos to @jdblischak! https://github.com/jdblischak/smk-simple-slurm
cluster:
  mkdir -p {OUTDIR}/logs/{rule} &&
  sbatch
    --partition={resources.partition}
    --time={resources.time}
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --job-name={rule}.{jobid}
    --output={OUTDIR}/logs/{rule}/{rule}_{wildcards}_%J.out
    --error={OUTDIR}/logs/{rule}/{rule}_{wildcards}_%J.err
default-resources:
  - partition=medium #eg. 'medium' or 'fat' (if in doubt, contact your local HPC support)
  - time="1-00:00:00" # maximum runtime of jobs, here 1 day / 24h
  - mem_mb=150000 # required memory per node, here in MB
max-jobs-per-second: 1
max-status-checks-per-second: 10
local-cores: 1
latency-wait: 60
jobs: 100
keep-going: True
rerun-incomplete: True
printshellcmds: True
scheduler: greedy
use-conda: True
conda-frontend: mamba
touch: False
reason: True
show-failed-logs: True
